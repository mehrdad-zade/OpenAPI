{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Andrej Karpathy's /makemore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference\n",
    "https://www.youtube.com/watch?v=TCH_1BHY58I\n",
    "\n",
    "https://github.com/karpathy/makemore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Bigram char level model, we only used two chars which created a 27x27 data space. if we move deeper in this approach to enhance the loss function and the model itself, the only avenue was to explor adding more dimensions, i.e. 27x27x27. however this path suddenly explodes in terms of data and parameters that we want to use for this model.\n",
    "\n",
    "Therefore, we need to explore a better model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron (MLP)\n",
    "#### Bengio et al. 2003\n",
    "\n",
    "This is another char level model to predict the next char, however the paper is based on word predictions. \n",
    "\n",
    "The proposed approach is to take 'w' number of words, and associate to each word, 'm' number of feature vectors. Meaning that, each word is embedded in a 'm' dimensional feature space. Initially these words are initialized randomly but later we'll tune them using backpropagation. \n",
    "\n",
    "To imagine this approach, think about words that are similar or synonyms. They will end up in the same part of the space. And those that are different will be separated. \n",
    "\n",
    "The modeling approach is similar to the NN approach for Bigram. They use multi-layer NN to predict the next words, given the previous words. To train the NN, they ```maximize the log-likelihood of the training data```.\n",
    "\n",
    "Let's look at an ```example``` for this approach. Assume, we are not given the sentence \"A dog was running in a room\". But now for testing the model we are providing it with \"A dog was running in a ...\" and expecting the model to fill in the blank. Since it hasn't seen this exact sentence, we call it, ```out of distribution```. However, MLP doesn't need to have seen the exact words to predict 'room' for the blank. Because it might have seen \"The dog was running in a room\" and based on the learnings, it has put the embeddings of 'The' and 'A' near by each other in the space. So now that we are asking it to fill the blank based on \"A dog was running in a ...\", it will match it up with \"The dog was running in a room\". This is called ```knowledge transfer```.\n",
    "\n",
    "Let's look at the ```architecture``` of this approach. \n",
    "\n",
    "Assume the NN's input, takes 3 previous-words. And the output is the fourth word. Each of the incoming words, will go through a look-up table, to match up the corresponding embedding ('m' feature vector) for that word. So there will be $3 \\times m$ neurons holding the 3 words. \n",
    "\n",
    "Then we need to build a hidden layer. The size is a ```hyper-parameter```. Meaning that, we need to come up with the right size based on try-error. So all the input neurons goes into the hidden layer. And there will be a ```tanh``` function applied for non-linearity. \n",
    "\n",
    "The output layer is a huge one, because the number of neurons is equivalent to $w$, the number of words in our data set. All the neurons in the hidden layer are connected to the output neurons. That's why there will be lots of params in between these two layers, and therefore, it's going to be computationally expensive. On top of the output layer we have ```softmax``` (exponentiate the logits and normalize, so that it will sum up to 1). This way, we'll get a nice probability distribution for the next word in the sequence. \n",
    "\n",
    "During training, because we have xs and ys, we will get the probability for each x and minimize the NN's loss by improving the parameters. The optimization used here is also ```backpropagation```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# read from another package while we are in a separate package\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "file_path = os.path.join(parent_directory, 'opensource/makemore', 'names.txt')\n",
    "\n",
    "words = open(file_path, 'r').read().splitlines()\n",
    "\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of chars and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "s2i = {s:i+1 for i,s in enumerate(chars)}\n",
    "s2i['.'] = 0\n",
    "i2s = {i:s for s,i in s2i.items()}\n",
    "print(i2s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context length: how many chars do we take to predict the next char, 4-th one\n",
    "X, Y = [], []\n",
    "for w in words[:5]: # the examples we can generate from the first 5 words\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.': # we are padding with dots, because if the word doesn't have enough chars to cover for our block_size, we'll have something to build\n",
    "        ix = s2i[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(i2s[i] for i in context), '--->', i2s[ix])\n",
    "        context = context[1:] + [ix] # crop and append\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 15],\n",
       "        [ 0, 15, 12],\n",
       "        [15, 12,  9],\n",
       "        [12,  9, 22],\n",
       "        [ 9, 22,  9],\n",
       "        [22,  9,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  1, 22],\n",
       "        [ 1, 22,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  9],\n",
       "        [ 0,  9, 19],\n",
       "        [ 9, 19,  1],\n",
       "        [19,  1,  2],\n",
       "        [ 1,  2,  5],\n",
       "        [ 2,  5, 12],\n",
       "        [ 5, 12, 12],\n",
       "        [12, 12,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 19],\n",
       "        [ 0, 19, 15],\n",
       "        [19, 15, 16],\n",
       "        [15, 16,  8],\n",
       "        [16,  8,  9],\n",
       "        [ 8,  9,  1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build The Embeddings\n",
    "\n",
    "the paper used 70000 words with 30 embeddings. we have 27 chars, so we'll go with 2 embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3131, 0.0140])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.randn((27, 2))\n",
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.3131,  0.0140],\n",
       "        [-0.6978,  0.8964],\n",
       "        [-0.5446,  1.6925]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve embeddings with a list of lookups\n",
    "C[[5,6,8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4846, -0.9307],\n",
       "         [-1.4846, -0.9307],\n",
       "         [-1.4846, -0.9307]],\n",
       "\n",
       "        [[-1.4846, -0.9307],\n",
       "         [-1.4846, -0.9307],\n",
       "         [ 2.3131,  0.0140]],\n",
       "\n",
       "        [[-1.4846, -0.9307],\n",
       "         [ 2.3131,  0.0140],\n",
       "         [-0.4677, -0.6155]],\n",
       "\n",
       "        [[ 2.3131,  0.0140],\n",
       "         [-0.4677, -0.6155],\n",
       "         [-0.4677, -0.6155]],\n",
       "\n",
       "        [[-0.4677, -0.6155],\n",
       "         [-0.4677, -0.6155],\n",
       "         [ 1.7267,  0.5913]],\n",
       "\n",
       "        [[-1.4846, -0.9307],\n",
       "         [-1.4846, -0.9307],\n",
       "         [-1.4846, -0.9307]],\n",
       "\n",
       "        [[-1.4846, -0.9307],\n",
       "         [-1.4846, -0.9307],\n",
       "         [ 0.9399,  1.0661]],\n",
       "\n",
       "        [[-1.4846, -0.9307],\n",
       "         [ 0.9399,  1.0661],\n",
       "         [-0.9957, -0.7736]],\n",
       "\n",
       "        [[ 0.9399,  1.0661],\n",
       "         [-0.9957, -0.7736],\n",
       "         [-0.7113, -0.3796]],\n",
       "\n",
       "        [[-0.9957, -0.7736],\n",
       "         [-0.7113, -0.3796],\n",
       "         [-0.1170, -0.3380]],\n",
       "\n",
       "        [[-0.7113, -0.3796],\n",
       "         [-0.1170, -0.3380],\n",
       "         [-0.7113, -0.3796]],\n",
       "\n",
       "        [[-0.1170, -0.3380],\n",
       "         [-0.7113, -0.3796],\n",
       "         [ 1.7267,  0.5913]],\n",
       "\n",
       "        [[-1.4846, -0.9307],\n",
       "         [-1.4846, -0.9307],\n",
       "         [-1.4846, -0.9307]],\n",
       "\n",
       "        [[-1.4846, -0.9307],\n",
       "         [-1.4846, -0.9307],\n",
       "         [ 1.7267,  0.5913]],\n",
       "\n",
       "        [[-1.4846, -0.9307],\n",
       "         [ 1.7267,  0.5913],\n",
       "         [-0.1170, -0.3380]],\n",
       "\n",
       "        [[ 1.7267,  0.5913],\n",
       "         [-0.1170, -0.3380],\n",
       "         [ 1.7267,  0.5913]],\n",
       "\n",
       "        [[-1.4846, -0.9307],\n",
       "         [-1.4846, -0.9307],\n",
       "         [-1.4846, -0.9307]],\n",
       "\n",
       "        [[-1.4846, -0.9307],\n",
       "         [-1.4846, -0.9307],\n",
       "         [-0.7113, -0.3796]],\n",
       "\n",
       "        [[-1.4846, -0.9307],\n",
       "         [-0.7113, -0.3796],\n",
       "         [-0.8162, -0.2788]],\n",
       "\n",
       "        [[-0.7113, -0.3796],\n",
       "         [-0.8162, -0.2788],\n",
       "         [ 1.7267,  0.5913]],\n",
       "\n",
       "        [[-0.8162, -0.2788],\n",
       "         [ 1.7267,  0.5913],\n",
       "         [-1.2056,  0.7466]],\n",
       "\n",
       "        [[ 1.7267,  0.5913],\n",
       "         [-1.2056,  0.7466],\n",
       "         [ 2.3131,  0.0140]],\n",
       "\n",
       "        [[-1.2056,  0.7466],\n",
       "         [ 2.3131,  0.0140],\n",
       "         [-0.9957, -0.7736]],\n",
       "\n",
       "        [[ 2.3131,  0.0140],\n",
       "         [-0.9957, -0.7736],\n",
       "         [-0.9957, -0.7736]],\n",
       "\n",
       "        [[-0.9957, -0.7736],\n",
       "         [-0.9957, -0.7736],\n",
       "         [ 1.7267,  0.5913]],\n",
       "\n",
       "        [[-1.4846, -0.9307],\n",
       "         [-1.4846, -0.9307],\n",
       "         [-1.4846, -0.9307]],\n",
       "\n",
       "        [[-1.4846, -0.9307],\n",
       "         [-1.4846, -0.9307],\n",
       "         [-0.8162, -0.2788]],\n",
       "\n",
       "        [[-1.4846, -0.9307],\n",
       "         [-0.8162, -0.2788],\n",
       "         [ 0.9399,  1.0661]],\n",
       "\n",
       "        [[-0.8162, -0.2788],\n",
       "         [ 0.9399,  1.0661],\n",
       "         [-0.9600, -0.0385]],\n",
       "\n",
       "        [[ 0.9399,  1.0661],\n",
       "         [-0.9600, -0.0385],\n",
       "         [-0.5446,  1.6925]],\n",
       "\n",
       "        [[-0.9600, -0.0385],\n",
       "         [-0.5446,  1.6925],\n",
       "         [-0.7113, -0.3796]],\n",
       "\n",
       "        [[-0.5446,  1.6925],\n",
       "         [-0.7113, -0.3796],\n",
       "         [ 1.7267,  0.5913]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# therefore this works\n",
    "emb = C[X]\n",
    "emb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_hyperparameter_size = 100\n",
    "num_of_words = 3\n",
    "num_of_embeddings = 2\n",
    "num_of_inputs = num_of_words * num_of_embeddings\n",
    "\n",
    "w1 = torch.randn((num_of_inputs, hidden_layer_hyperparameter_size))\n",
    "b1 = torch.randn((hidden_layer_hyperparameter_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 100])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wee want to setup the tensor's shapes in such a way that ```emb @ w1 + b1``` would work.\n",
    "\n",
    "http://blog.ezyang.com/2019/05/pytorch-internals/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5943, -0.8644,  0.8524,  ...,  5.1608, -1.5512, -0.1240],\n",
       "        [-0.1756,  6.6545, -4.5579,  ...,  1.7516,  2.5350,  0.3815],\n",
       "        [-1.0892, -3.7104, -3.1708,  ...,  2.3125,  1.7632, -2.0210],\n",
       "        ...,\n",
       "        [ 1.3089,  4.0530,  1.7895,  ...,  6.5008, -0.4606,  1.8410],\n",
       "        [ 2.3053,  1.1875, -0.6656,  ...,  6.1175, -0.4204,  2.4052],\n",
       "        [ 2.9902,  6.7687, -2.5202,  ...,  1.9511, -1.7564,  2.0530]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_size = emb.shape[0] # or use -1 for pytorch to figure it out\n",
    "emb.view(x_size, num_of_inputs) @ w1 + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9889, -0.6985,  0.6923,  ...,  0.9999, -0.9140, -0.1234],\n",
       "        [-0.1738,  1.0000, -0.9998,  ...,  0.9416,  0.9875,  0.3640],\n",
       "        [-0.7966, -0.9988, -0.9965,  ...,  0.9806,  0.9429, -0.9655],\n",
       "        ...,\n",
       "        [ 0.8640,  0.9994,  0.9457,  ...,  1.0000, -0.4306,  0.9509],\n",
       "        [ 0.9803,  0.8298, -0.5821,  ...,  1.0000, -0.3973,  0.9838],\n",
       "        [ 0.9950,  1.0000, -0.9871,  ...,  0.9604, -0.9421,  0.9676]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hidden layer\n",
    "h = torch.tanh(emb.view(-1, num_of_inputs) @ w1 + b1) # added tanh to bring all the values between -1 and 1 for non-linearity\n",
    "h "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output layer\n",
    "w2 = torch.randn((hidden_layer_hyperparameter_size, 27))\n",
    "b2 = torch.randn((27))\n",
    "logits = h @ w2 + b2\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = logits.exp() # get fake counts\n",
    "probs = counts / counts.sum(1, keepdim=True) # normalize to get the probabilities\n",
    "probs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proof of normalized probs is to check if every row sums up to =1\n",
    "probs[0].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
